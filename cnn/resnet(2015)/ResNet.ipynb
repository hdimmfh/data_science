{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 24px; font-weight: bold;\">🏋🏼‍♀️ ResNet Code</h1>\n",
    "\n",
    "<h3 style=\"font-size: 18px; font-weight: bold;\">⚽️&nbsp;&nbsp;&nbsp;version control</h3>\n",
    "<ul style=\"list-style-type: none; padding: 0;\">\n",
    "    <li style=\"font-size: 14px;\">python(3.8.17)</li>\n",
    "    <li style=\"font-size: 14px;\">torch(2.1.2)</li>\n",
    "    <li style=\"font-size: 14px;\">torchsummary(1.5.1)</li>\n",
    "    <li style=\"font-size: 14px;\">torchvision(0.16.2)</li>\n",
    "</ul>\n",
    "\n",
    "<div style=\"font-size: 14px;\">( Actually, I believe the version of Torch doesn't make a difference. )</div>\n",
    "\n",
    "<h3 style=\"font-size: 18px; font-weight: bold;\">🏀&nbsp;&nbsp;&nbsp;main idea</h3>\n",
    "<br/>\n",
    "<img src=\"./refer1.png\" alt=\"ResNet Layer Example\" width=\"400\"/>\n",
    "<div style=\"display: flex; align-items: start;\">\n",
    "    <div style=\"width: 200px; height: 15px; font-size: 14px;\">↑standard</div>\n",
    "    <div style=\"width: 200px; height: 15px; font-size: 14px;\">↑bottleneck</div>\n",
    "</div>\n",
    "\n",
    "<ol style=\"padding-left: 20px;\">\n",
    "    <li style=\"font-size: 14px;\">Input(Batch size, 256, 320, 320)</li>\n",
    "    <li style=\"font-size: 14px;\">\n",
    "        Convolution 1x1, out 64 <br/>\n",
    "        - kernel, channel reduction → computational complexity reduction <br/>\n",
    "        - (kernel: 1*1) → without feature extraction \n",
    "    </li>\n",
    "    <li style=\"font-size: 14px;\">Convolution 3x3, out 64 <br/>\n",
    "        - (kernel: 3*3) → feature extraction \n",
    "    </li>\n",
    "    <li style=\"font-size: 14px;\">\n",
    "        Convolution 1x1, out 256 <br/>\n",
    "        - channel increase → learning features ↑\n",
    "    </li>\n",
    "</ol>\n",
    "\n",
    "<img src=\"./refer2.png\" alt=\"ResNet Layer Composition\" width=\"500\">\n",
    "<p style=\"font-size: 14px;\">- Applying the aforementioned concept across a network with over 50 layers</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "! pip install torch \n",
    "! pip install torchvision\n",
    "! pip install torchsummary\n",
    "! pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T13:08:44.962578Z",
     "start_time": "2024-01-17T13:08:42.972240Z"
    }
   },
   "outputs": [],
   "source": [
    "# import package\n",
    "\n",
    "# model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "# dataset and transformation\n",
    "from torchvision.datasets import STL10\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# display images\n",
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# utils\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 다운로드 및 저장 경로 지정\n",
    "data_path = './stl10_data'\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "    \n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# STL-10 데이터셋 다운로드\n",
    "train_dataset = STL10(root=data_path, split='train', download=False, transform=transform)\n",
    "test_dataset = STL10(root=data_path, split='test', download=False, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(train_dataset.classes))\n",
    "print(len(test_dataset))\n",
    "print(len(test_dataset.classes))\n",
    "\n",
    "# Example output :\n",
    "# 5000\n",
    "# 10\n",
    "# 8000\n",
    "# 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To normalize the dataset, calculate the mean and std\n",
    "train_meanRGB = [np.mean(x.numpy(), axis=(1,2)) for x, _ in train_dataset]\n",
    "train_stdRGB = [np.std(x.numpy(), axis=(1,2)) for x, _ in train_dataset]\n",
    "\n",
    "train_meanR = np.mean([m[0] for m in train_meanRGB])\n",
    "train_meanG = np.mean([m[1] for m in train_meanRGB])\n",
    "train_meanB = np.mean([m[2] for m in train_meanRGB])\n",
    "train_stdR = np.mean([s[0] for s in train_stdRGB])\n",
    "train_stdG = np.mean([s[1] for s in train_stdRGB])\n",
    "train_stdB = np.mean([s[2] for s in train_stdRGB])\n",
    "\n",
    "\n",
    "val_meanRGB = [np.mean(x.numpy(), axis=(1,2)) for x, _ in test_dataset]\n",
    "val_stdRGB = [np.std(x.numpy(), axis=(1,2)) for x, _ in test_dataset]\n",
    "\n",
    "val_meanR = np.mean([m[0] for m in val_meanRGB])\n",
    "val_meanG = np.mean([m[1] for m in val_meanRGB])\n",
    "val_meanB = np.mean([m[2] for m in val_meanRGB])\n",
    "\n",
    "val_stdR = np.mean([s[0] for s in val_stdRGB])\n",
    "val_stdG = np.mean([s[1] for s in val_stdRGB])\n",
    "val_stdB = np.mean([s[2] for s in val_stdRGB])\n",
    "\n",
    "print(train_meanR, train_meanG, train_meanB)\n",
    "print(val_meanR, val_meanG, val_meanB)\n",
    "\n",
    "# Example output :\n",
    "# -0.106578745 -0.1203803 -0.18670711\n",
    "# -0.105538726 -0.120715044 -0.19008549"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the image transformation\n",
    "train_transformation = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Resize(224),\n",
    "                        transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                        transforms.RandomHorizontalFlip(),\n",
    "])\n",
    "\n",
    "val_transformation = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Resize(224),\n",
    "                        transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply transforamtion\n",
    "train_dataset.transform = train_transformation\n",
    "test_dataset.transform = val_transformation\n",
    "\n",
    "# create DataLoader\n",
    "train_dl = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dl = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display sample images \n",
    "def show(img, y=None, color=True):\n",
    "    npimg = img.numpy()\n",
    "    npimg_tr = np.transpose(npimg, (1,2,0))\n",
    "    plt.imshow(npimg_tr)\n",
    "\n",
    "    if y is not None:\n",
    "        plt.title('labels :' + str(y))\n",
    "\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "grid_size = 4\n",
    "rnd_inds = np.random.randint(0, len(train_dataset), grid_size)\n",
    "print('image indices:',rnd_inds)\n",
    "\n",
    "x_grid = [train_dataset[i][0] for i in rnd_inds]\n",
    "y_grid = [train_dataset[i][1] for i in rnd_inds]\n",
    "\n",
    "x_grid = utils.make_grid(x_grid, nrow=grid_size, padding=2)\n",
    "\n",
    "show(x_grid, y_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # BatchNorm에 bias가 포함되어 있으므로, conv2d는 bias=False로 설정합니다.\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BasicBlock.expansion),\n",
    "        )\n",
    "\n",
    "        # identity mapping, input과 output의 feature map size, filter 수가 동일한 경우 사용.\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # projection mapping using 1x1conv\n",
    "        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels*BottleNeck.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels*BottleNeck.expansion)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_block, num_classes=10, init_weights=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels=64\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
    "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
    "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
    "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        # weights inittialization\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2_x(output)\n",
    "        x = self.conv3_x(output)\n",
    "        x = self.conv4_x(x)\n",
    "        x = self.conv5_x(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    # define weight initialization function\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "def resnet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "def resnet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "def resnet50():\n",
    "    return ResNet(BottleNeck, [3,4,6,3])\n",
    "\n",
    "def resnet101():\n",
    "    return ResNet(BottleNeck, [3, 4, 23, 3])\n",
    "\n",
    "def resnet152():\n",
    "    return ResNet(BottleNeck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = resnet50().to(device)\n",
    "x = torch.randn(3, 3, 224, 224).to(device)\n",
    "output = model(x)\n",
    "print(output.size())\n",
    "# Example output :\n",
    "#torch.Size([3, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, (3, 224, 224), device=device.type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
    "opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get current lr\n",
    "def get_lr(opt):\n",
    "    for param_group in opt.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate metric per mini-batch\n",
    "def metric_batch(output, target):\n",
    "    pred = output.argmax(1, keepdim=True)\n",
    "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
    "    return corrects\n",
    "\n",
    "\n",
    "# function to calculate loss per mini-batch\n",
    "def loss_batch(loss_func, output, target, opt=None):\n",
    "    loss = loss_func(output, target)\n",
    "    metric_b = metric_batch(output, target)\n",
    "\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return loss.item(), metric_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate loss and metric per epoch\n",
    "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
    "    running_loss = 0.0\n",
    "    running_metric = 0.0\n",
    "    len_data = len(dataset_dl.dataset)\n",
    "\n",
    "    for xb, yb in dataset_dl:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        output = model(xb)\n",
    "\n",
    "        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
    "\n",
    "        running_loss += loss_b\n",
    "        \n",
    "        if metric_b is not None:\n",
    "            running_metric += metric_b\n",
    "        \n",
    "        if sanity_check is True:\n",
    "            break\n",
    "\n",
    "    loss = running_loss / len_data\n",
    "    metric = running_metric / len_data\n",
    "\n",
    "    return loss, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to start training\n",
    "def train_val(model, params):\n",
    "    num_epochs=params['num_epochs']\n",
    "    loss_func=params[\"loss_func\"]\n",
    "    opt=params[\"optimizer\"]\n",
    "    train_dl=params[\"train_dl\"]\n",
    "    val_dl=params[\"val_dl\"]\n",
    "    sanity_check=params[\"sanity_check\"]\n",
    "    lr_scheduler=params[\"lr_scheduler\"]\n",
    "    path2weights=params[\"path2weights\"]\n",
    "\n",
    "    loss_history = {'train': [], 'val': []}\n",
    "    metric_history = {'train': [], 'val': []}\n",
    "\n",
    "    # # GPU out of memoty error\n",
    "    # best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        current_lr = get_lr(opt)\n",
    "        print('Epoch {}/{}, current lr={}'.format(epoch, num_epochs-1, current_lr))\n",
    "\n",
    "        model.train()\n",
    "        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
    "        loss_history['train'].append(train_loss)\n",
    "        metric_history['train'].append(train_metric)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n",
    "        loss_history['val'].append(val_loss)\n",
    "        metric_history['val'].append(val_metric)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            # best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            # torch.save(model.state_dict(), path2weights)\n",
    "            # print('Copied best model weights!')\n",
    "            print('Get best val_loss')\n",
    "\n",
    "        lr_scheduler.step(val_loss)\n",
    "\n",
    "        print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
    "        print('-'*10)\n",
    "\n",
    "    # model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, loss_history, metric_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definc the training parameters\n",
    "params_train = {\n",
    "    'num_epochs':20,\n",
    "    'optimizer':opt,\n",
    "    'loss_func':loss_func,\n",
    "    'train_dl':train_dl,\n",
    "    'val_dl':val_dl,\n",
    "    'sanity_check':False,\n",
    "    'lr_scheduler':lr_scheduler,\n",
    "    'path2weights':'./models/weights.pt',\n",
    "}\n",
    "\n",
    "# create the directory that stores weights.pt\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except Exception:\n",
    "        print('Error')\n",
    "createFolder('./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Validation Progress\n",
    "num_epochs=params_train[\"num_epochs\"]\n",
    "\n",
    "# plot loss progress\n",
    "plt.title(\"Train-Val Loss\")\n",
    "plt.plot(range(1,num_epochs+1),loss_hist[\"train\"],label=\"train\")\n",
    "plt.plot(range(1,num_epochs+1),loss_hist[\"val\"],label=\"val\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot accuracy progress\n",
    "plt.title(\"Train-Val Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),metric_hist[\"train\"],label=\"train\")\n",
    "plt.plot(range(1,num_epochs+1),metric_hist[\"val\"],label=\"val\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
